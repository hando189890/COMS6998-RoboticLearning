# COMS 6998 Topic Robotic Learning

In this project, we focused on using pre-trained visual feature representation to guide potential robot manipulation tasks. We present an accurate, real-time approach to robotic grasp detection based on DenseNet. We first pretrain DenseNet model on out-of-domain Imagenet data, and then apply it to robotics tasks to predict grasping boxes from a given image. We assessed the performance of grasping detection using point and rectangle evaluation metrics. 

## Group Members
- Tianxiao He (th2946)
- Dongbing Han (dh3071)
- Sheng Gao (sg3967)
- Shenfeng Gu (sg4152)

## Links
- Github: [https://github.com/hando189890/COMS6998-RoboticLearning]
- Proposal Presentation: [https://docs.google.com/presentation/d/16yrecPwV0sc78Oomdbf7-cbnX27SWhLsZEzHpCaf-LU/edit#slide=id.g16953bd4e93_0_6]
